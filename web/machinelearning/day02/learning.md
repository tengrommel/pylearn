# 算法分类
- 监督学习
  - 函数的输出可以是一个连续的值
  - 或是输出是有限个数离散值（称作分类）
- 无监督学习
- 半监督学习
- 强化学习

# 正则化
> 通过限制高次项的系数进行防止过拟合
- Lasso回归
> 直接把高次项前面的系数变为0
- 岭回归
> 把高次项系数前面的系数变成特别小的值

# 正则化线性模型

Ridge Regression 岭回归
   
   - 就是把系数前面添加平方项
   - 然后限制数值的大小
   - α值越小，系数值越大，α越大，系数值越小

Lasso回归

   - 对系数值进行绝对值处理
   - 由于绝对值在顶点处不可导，所以进行计算的过程中产生很多0，最后得到结果为：稀疏矩阵

弹性网络
> 混合了岭回归和Lasso 设置了一个r，如果r=0 为岭回归 如果r=1 为Lasso回归

Early Stopping

